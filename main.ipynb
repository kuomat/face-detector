{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import urllib.request"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml():\n",
    "    url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    xml_bytes = response.read()\n",
    "\n",
    "    # Load the classifier\n",
    "    xml_string = xml_bytes.decode('utf-8')\n",
    "    fs = cv2.FileStorage(xml_string, cv2.FILE_STORAGE_READ | cv2.FILE_STORAGE_MEMORY)\n",
    "    return fs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(filepath, start_time, end_time, start_frame, end_frame, fs):\n",
    "    # Path to video file\n",
    "    vid_obj = cv2.VideoCapture(filepath)\n",
    "\n",
    "    # FPS of the video\n",
    "    fps = int(vid_obj.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # How much we are scaling each frame by when detecting faces\n",
    "    scale_factor = int(vid_obj.get(cv2.CAP_PROP_FRAME_WIDTH)) / 500\n",
    "\n",
    "    rows = []\n",
    "    frame_count = 0\n",
    "\n",
    "    # Load face detector\n",
    "    detector = cv2.CascadeClassifier()\n",
    "    detector.read(fs.getFirstTopLevelNode())\n",
    "\n",
    "    # Get the starting frame (the lower of start_time or start_frame)\n",
    "    start_time_frame = start_time * fps\n",
    "    start_frame = min(start_time_frame, start_frame)\n",
    "\n",
    "    # Get the ending frame (the higher of end_time or end_frame)\n",
    "    if end_time is None:\n",
    "        if end_frame is None:\n",
    "            end_frame = int(vid_obj.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            end_time = end_frame / fps\n",
    "        else:\n",
    "            end_time = end_frame / fps\n",
    "    else:\n",
    "        if end_frame is None:\n",
    "            end_frame = int(end_time * fps)\n",
    "        else:\n",
    "            end_frame = max(end_frame, int(end_time * fps))\n",
    "            end_time = end_frame / fps\n",
    "\n",
    "    # Create an empty numpy array to store face coordinates\n",
    "    face_coords = np.zeros((end_frame - start_frame + 1, 4))\n",
    "\n",
    "    # Skip frames before start_time\n",
    "    while frame_count < start_frame:\n",
    "        success = vid_obj.grab()\n",
    "        if not success:\n",
    "            return start_time, end_time, start_frame, end_frame, fps, pd.DataFrame(rows)\n",
    "        frame_count += 1\n",
    "\n",
    "    while True:\n",
    "        # Read the next video object\n",
    "        success, image = vid_obj.read()\n",
    "\n",
    "        # End when reaches end_frame\n",
    "        if not success or frame_count > end_frame:\n",
    "            break\n",
    "\n",
    "        # Resize image and convert it to grayscale\n",
    "        image = imutils.resize(image, width=500)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in image using the haar cascade face detector\n",
    "        rects = detector.detectMultiScale(image=gray,\n",
    "                                          scaleFactor=1.1,\n",
    "                                          minNeighbors=9,\n",
    "                                          flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        # Extract x,y,w,h of each rect and store in numpy array\n",
    "        for i, (x, y, w, h) in enumerate(rects):\n",
    "            face_coords[frame_count - start_frame + i, :] = np.array([x * scale_factor, y * scale_factor, w * scale_factor, h * scale_factor])\n",
    "\n",
    "        frame_count += len(rects)\n",
    "\n",
    "    # Convert numpy array to pandas dataframe\n",
    "    rows = [{'frame': i} for i in range(start_frame, end_frame + 1)]\n",
    "    rows = pd.DataFrame(rows)\n",
    "    rows[['x', 'y', 'w', 'h']] = pd.DataFrame(face_coords)\n",
    "\n",
    "    vid_obj.release()\n",
    "    return start_time, end_time, start_frame, end_frame, fps, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>423.36</td>\n",
       "      <td>758.16</td>\n",
       "      <td>324.00</td>\n",
       "      <td>324.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>419.04</td>\n",
       "      <td>756.00</td>\n",
       "      <td>330.48</td>\n",
       "      <td>330.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>414.72</td>\n",
       "      <td>753.84</td>\n",
       "      <td>334.80</td>\n",
       "      <td>334.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame       x       y       w       h\n",
       "0      0  423.36  758.16  324.00  324.00\n",
       "1      1  419.04  756.00  330.48  330.48\n",
       "2      2  414.72  753.84  334.80  334.80"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = './ML0001_1.mp4'\n",
    "# def extract_faces(filepath, start_time, end_time, start_frame, end_frame):\n",
    "fs = read_xml()\n",
    "start_time, end_time, start_frame, end_frame, fps, video_df = test(video_path, 0, None, 0, None, fs)\n",
    "video_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/matthewkuo/Desktop/software-pipeline/main.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewkuo/Desktop/software-pipeline/main.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m video_obj\u001b[39m.\u001b[39mset(cv2\u001b[39m.\u001b[39mCAP_PROP_POS_FRAMES, row[\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewkuo/Desktop/software-pipeline/main.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ret, frame \u001b[39m=\u001b[39m video_obj\u001b[39m.\u001b[39mread()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matthewkuo/Desktop/software-pipeline/main.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x, y, w, h \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(row[\u001b[39m'\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m'\u001b[39;49m]), \u001b[39mint\u001b[39m(row[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mint\u001b[39m(row[\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mint\u001b[39m(row[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewkuo/Desktop/software-pipeline/main.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m cv2\u001b[39m.\u001b[39mrectangle(frame, (x, y), (x \u001b[39m+\u001b[39m w, y \u001b[39m+\u001b[39m h), (\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewkuo/Desktop/software-pipeline/main.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mFrame with bounding box\u001b[39m\u001b[39m\"\u001b[39m, frame)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "video_obj = cv2.VideoCapture(video_path)\n",
    "\n",
    "for index, row in video_df.iterrows():\n",
    "    # read the frame from the video\n",
    "    video_obj.set(cv2.CAP_PROP_POS_FRAMES, row['frame'])\n",
    "    ret, frame = video_obj.read()\n",
    "    \n",
    "    x, y, w, h = int(row['x']), int(row['y']), int(row['w']), int(row['h'])\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame with bounding box\", frame)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# Release the video object and close all windows\n",
    "video_obj.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from datetime import datetime\n",
    "\n",
    "def json_converter(filename, video_metadata):\n",
    "    # Get today's date\n",
    "    creation_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Convert video_metadata into appropriate format\n",
    "    start_time, end_time, start_frame, end_frame, fps, video_df = video_metadata\n",
    "\n",
    "    rows_dict = {}\n",
    "    for index, row in video_df.iterrows():\n",
    "        key = \"FrameNumber\" + str(row['frame'])\n",
    "        values = {\"FrameCoordinates\": [str(row['x']), str(row['y']), str(row['w']), str(row['h'])]}\n",
    "        rows_dict[key] = values\n",
    "\n",
    "    json_obj = {\n",
    "        \"VideoInformation\": filename,\n",
    "        \"CreationDate\": creation_date,\n",
    "        \"VideoMetadata\": {\n",
    "            \"StartTime\": start_time,\n",
    "            \"EndTime\": end_time,\n",
    "            \"StartFrame\": start_frame,\n",
    "            \"EndFrame\": end_frame,\n",
    "            \"Fps\": fps,\n",
    "            \"FrameData\": rows_dict\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return json.dumps(json_obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time should be in seconds\n",
    "def face_detector(filename, filepath, start_time=0, end_time=None, start_frame=0, end_frame=None):\n",
    "    fs = read_xml()\n",
    "    video_metadata = extract_faces(filepath, start_time, end_time, start_frame, end_frame, fs)\n",
    "    return json_converter(filename, video_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"VideoInformation\": \"test_file\", \"CreationDate\": \"2023-04-07\", \"VideoMetadata\": {\"StartTime\": 0, \"EndTime\": 1.0, \"StartFrame\": 0, \"EndFrame\": 30, \"Fps\": 30, \"FrameData\": {\"FrameNumber0\": {\"FrameCoordinates\": [\"196\", \"351\", \"150\", \"150\"]}, \"FrameNumber1\": {\"FrameCoordinates\": [\"194\", \"350\", \"153\", \"153\"]}, \"FrameNumber2\": {\"FrameCoordinates\": [\"192\", \"349\", \"155\", \"155\"]}, \"FrameNumber3\": {\"FrameCoordinates\": [\"192\", \"350\", \"153\", \"153\"]}, \"FrameNumber4\": {\"FrameCoordinates\": [\"193\", \"353\", \"151\", \"151\"]}, \"FrameNumber5\": {\"FrameCoordinates\": [\"194\", \"353\", \"150\", \"150\"]}, \"FrameNumber6\": {\"FrameCoordinates\": [\"193\", \"353\", \"151\", \"151\"]}, \"FrameNumber7\": {\"FrameCoordinates\": [\"192\", \"352\", \"153\", \"153\"]}, \"FrameNumber8\": {\"FrameCoordinates\": [\"191\", \"352\", \"155\", \"155\"]}, \"FrameNumber9\": {\"FrameCoordinates\": [\"191\", \"351\", \"155\", \"155\"]}, \"FrameNumber10\": {\"FrameCoordinates\": [\"191\", \"351\", \"155\", \"155\"]}, \"FrameNumber11\": {\"FrameCoordinates\": [\"192\", \"351\", \"154\", \"154\"]}, \"FrameNumber12\": {\"FrameCoordinates\": [\"192\", \"352\", \"154\", \"154\"]}, \"FrameNumber13\": {\"FrameCoordinates\": [\"193\", \"352\", \"153\", \"153\"]}, \"FrameNumber14\": {\"FrameCoordinates\": [\"196\", \"353\", \"152\", \"152\"]}, \"FrameNumber15\": {\"FrameCoordinates\": [\"197\", \"352\", \"153\", \"153\"]}, \"FrameNumber16\": {\"FrameCoordinates\": [\"201\", \"355\", \"148\", \"148\"]}, \"FrameNumber17\": {\"FrameCoordinates\": [\"204\", \"354\", \"150\", \"150\"]}, \"FrameNumber18\": {\"FrameCoordinates\": [\"212\", \"361\", \"138\", \"138\"]}, \"FrameNumber19\": {\"FrameCoordinates\": [\"215\", \"359\", \"144\", \"144\"]}}}}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_detector('test_file', './ML0001_1.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
